{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import simplejson as json\n",
    "from sklearn.feature_extraction.text import * \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a bag of words (BOW) representation from text documents, using the Vectorizer function in scikit-learn\n",
    "# Inputs:\n",
    "#  - file name \n",
    "#  - the min_pos and max_neg parameters\n",
    "#  - all reviews with scores => min_pos = 4 are labeled \"1\"  \n",
    "#  - all reviews with scores <= max_neg = 2 ae labeled \"0\" \n",
    "#  - this creates a simple set of labels for binary classification, ignoring the neutral (score = 3) reviews\n",
    "# \n",
    "#  The function extracts the text and scores for each review from the JSON data\n",
    "#  It then tokenizes and creates a sparse bag-of-words array using scikit-learn vectorizer function\n",
    "#  The number of rows in the array is the number of reviews with scores <=2 or >=4\n",
    "#  The number of columns in the array is the number of terms in the vocabulary\n",
    "def create_bow_from_reviews(filename, min_pos=4, max_neg=2): \n",
    "    \n",
    "    print('\\nLoading the file: \\n', filename) \n",
    "    with open(filename, 'r') as jfile:\n",
    "        data = json.load(jfile)\n",
    "    print('\\nTotal number of reviews extracted =', len(data) )\n",
    "\n",
    "    text = []\n",
    "    Y = []\n",
    "    lengths = []\n",
    "    print('\\nExtracting tokens from each review.....(can be slow for a large number of reviews)......')   \n",
    "    for d in data:\n",
    "        # keep only the text and label\n",
    "        review = d[\"text\"]\n",
    "        stars = d[\"stars\"]\n",
    "\n",
    "        # simple logic to generate a binary score for each review\n",
    "        if stars >= min_pos: score = 1\n",
    "        elif stars <= max_neg: score = 0\n",
    "        else: continue # Ignore 3 stars reviews (neutral)\n",
    "\n",
    "        text.append(review)   \n",
    "        Y.append(score)\n",
    "\n",
    "    # creates an instance of a CountVectorizer, using\n",
    "    # (1) the standard 'english' stopword set \n",
    "    # (2) only keeping terms in the vocabulary that occur in at least 1% of documents\n",
    "    # (3) allowing both unigrams and bigrams in the vocabulary\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df=0.01, ngram_range=(1, 2))\n",
    "\n",
    "    # creates a sparse BOW array from 'text' using vectorizer  \n",
    "    X = vectorizer.fit_transform(text)\n",
    "\n",
    "    print('Data shape: ', X.shape)\n",
    "\n",
    "    return X, Y, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classification(X, Y, test_fraction): \n",
    "    # This function creates and returns a Logistic Classifier for text using l2 penalty regularizer.\n",
    "    # Accuracy is computed for both training and test sets to fine tune the model and to reduce bias and variance problems.\n",
    "    # Parameters:\n",
    "    # X: A sparse Bag of Words created from text in reviews using CountVectorizer.\n",
    "    # Y: Binary labels (0 or 1) corresponding to each data in X.\n",
    "    # test_fraction: a real value representing split size for test. (1-test_fraction) will be used for training.\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "    random_state = 0\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])   \n",
    "    print('Vocabulary size: ', X_train.shape[1]) \n",
    "\n",
    "\n",
    "    # Specify the logistic classifier model with an l2 penalty for regularization and with fit_intercept turned on\n",
    "    classifier = linear_model.LogisticRegression(random_state = random_state, penalty=\"l2\", fit_intercept=True)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_predictions = classifier.predict(X_train)\n",
    "    train_accuracy = classifier.score(X_train, Y_train)\n",
    "    print('\\nTraining:')\n",
    "    print(' accuracy:',format( 100*train_accuracy , '.2f') ) \n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = classifier.score(X_test, Y_test)\n",
    "    print(' accuracy:', format( 100*test_accuracy , '.2f') )\n",
    "\n",
    "    class_probabilities = classifier.predict_proba(X_test)\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, test_predictions)\n",
    "    print(' AUC value:', format( 100*test_auc_score , '.2f') )\n",
    "\n",
    "    return(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_significant_terms(classifier, vectorizer, K):\n",
    "    topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms = [], [], [], []\n",
    "\n",
    "    weights = classifier.coef_ # Get feature weights from classifier\n",
    "    weight_pairs = zip(vectorizer.get_feature_names(), weights[0]) # Create pairs of (feature, weight)\n",
    "    weight_pairs = sorted(weight_pairs, key=lambda x: x[1]) # Sort by weight\n",
    "\n",
    "    # Print (term, weight) in order of largest weight first\n",
    "    print(\"\\nPositive Weights\")\n",
    "    for w in reversed(weight_pairs[-K:]):\n",
    "        topK_pos_terms.append(w[0])\n",
    "        topK_pos_weights.append(w[1])\n",
    "        print(w[0], format(w[1] , '.3f'))\n",
    "\n",
    "    # Print (term, weight) in order of most negative values first\n",
    "    print(\"\\nNegative Weights\")\n",
    "    for w in weight_pairs[:K]:\n",
    "        topK_neg_terms.append(w[0])\n",
    "        topK_neg_weights.append(w[1])\n",
    "        print(w[0], format(w[1] , '.3f'))\n",
    "\n",
    "    return(topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the file: \n",
      " yelp_reviews.json\n",
      "\n",
      "Total number of reviews extracted = 20000\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "Data shape:  (17501, 849)\n",
      "Number of training examples:  12250\n",
      "Number of testing examples:  5251\n",
      "Vocabulary size:  849\n",
      "\n",
      "Training a model with 12250 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 94.52\n",
      "\n",
      "Testing: \n",
      " accuracy: 90.94\n",
      " AUC value: 85.73\n"
     ]
    }
   ],
   "source": [
    "# read in the review text and tokenize the text in each review\n",
    "X, Y , vectorizer_BOW = create_bow_from_reviews('yelp_reviews.json')\n",
    "\n",
    "# run a logistic classifier on the reviews, specifying the fraction to be used for testing  \n",
    "test_fraction = 0.3\n",
    "logistic_classifier = logistic_classification(X, Y,test_fraction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive Weights\n",
      "pleased 2.265\n",
      "excellent 2.189\n",
      "delicious 2.058\n",
      "awesome 2.028\n",
      "enjoyed 2.023\n",
      "generous 1.888\n",
      "yum 1.872\n",
      "fantastic 1.834\n",
      "amazing 1.830\n",
      "gem 1.821\n",
      "perfect 1.806\n",
      "great service 1.693\n",
      "unique 1.659\n",
      "yummy 1.655\n",
      "wonderful 1.597\n",
      "world 1.572\n",
      "fabulous 1.539\n",
      "liked 1.515\n",
      "favorite 1.493\n",
      "highly recommend 1.485\n",
      "\n",
      "Negative Weights\n",
      "worst -3.246\n",
      "soggy -2.782\n",
      "horrible -2.550\n",
      "disappointing -2.383\n",
      "terrible -2.357\n",
      "bland -2.176\n",
      "rude -2.165\n",
      "waste -2.017\n",
      "unfortunately -1.716\n",
      "dry -1.706\n",
      "disappointed -1.696\n",
      "excited -1.638\n",
      "dirty -1.532\n",
      "poor -1.432\n",
      "salty -1.367\n",
      "okay -1.361\n",
      "happened -1.312\n",
      "taking -1.293\n",
      "ok -1.291\n",
      "fine -1.284\n"
     ]
    }
   ],
   "source": [
    "# print out and return the most significant positive and negative weights (and associated terms) \n",
    "topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms = most_significant_terms(logistic_classifier, vectorizer_BOW, K=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
